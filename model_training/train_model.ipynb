{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Freshness Predictor - Model Training\n",
        "\n",
        "This notebook fine-tunes a ResNet model for regression to predict days remaining until spoiled.\n",
        "\n",
        "## Dataset Structure\n",
        "Your dataset should be organized as follows:\n",
        "```\n",
        "dataset/\n",
        "  day_0/\n",
        "    image1.jpg\n",
        "    image2.jpg\n",
        "  day_1/\n",
        "    image1.jpg\n",
        "    ...\n",
        "  day_5/\n",
        "    image1.jpg\n",
        "    ...\n",
        "```\n",
        "\n",
        "Each folder name represents the number of days remaining until spoiled.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install tensorflow pillow numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 0.0001\n",
        "DATASET_PATH = \"/content/dataset\"  # Update this path\n",
        "MODEL_SAVE_PATH = \"/content/model.h5\"\n",
        "\n",
        "# Number of days (0-5)\n",
        "NUM_CLASSES = 6  # 0, 1, 2, 3, 4, 5 days\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and prepare dataset\n",
        "def load_dataset_from_folders(dataset_path):\n",
        "    \"\"\"\n",
        "    Load images from folder structure where folder names are day labels.\n",
        "    Returns: (images, labels) where labels are numeric (0-5)\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    \n",
        "    dataset_path = Path(dataset_path)\n",
        "    \n",
        "    for day_folder in sorted(dataset_path.iterdir()):\n",
        "        if not day_folder.is_dir():\n",
        "            continue\n",
        "            \n",
        "        # Extract day number from folder name (e.g., 'day_0' -> 0)\n",
        "        try:\n",
        "            day_label = int(day_folder.name.split('_')[1])\n",
        "        except:\n",
        "            print(f\"Skipping folder: {day_folder.name}\")\n",
        "            continue\n",
        "        \n",
        "        # Load all images in this folder\n",
        "        for img_file in list(day_folder.glob('*.jpg')) + list(day_folder.glob('*.png')):\n",
        "            img = keras.preprocessing.image.load_img(\n",
        "                img_file, target_size=IMG_SIZE\n",
        "            )\n",
        "            img_array = keras.preprocessing.image.img_to_array(img)\n",
        "            images.append(img_array)\n",
        "            labels.append(float(day_label))\n",
        "    \n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load dataset\n",
        "print(\"Loading dataset...\")\n",
        "images, labels = load_dataset_from_folders(DATASET_PATH)\n",
        "print(f\"Loaded {len(images)} images with labels shape: {labels.shape}\")\n",
        "print(f\"Label range: {labels.min()} to {labels.max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize images\n",
        "images = images / 255.0\n",
        "\n",
        "# Split into train and validation sets (80/20)\n",
        "split_idx = int(len(images) * 0.8)\n",
        "train_images = images[:split_idx]\n",
        "train_labels = labels[:split_idx]\n",
        "val_images = images[split_idx:]\n",
        "val_labels = labels[split_idx:]\n",
        "\n",
        "print(f\"Training samples: {len(train_images)}\")\n",
        "print(f\"Validation samples: {len(val_images)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the model\n",
        "# Load pre-trained ResNet50 (without top classification layer)\n",
        "base_model = ResNet50(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(*IMG_SIZE, 3)\n",
        ")\n",
        "\n",
        "# Freeze base model initially\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom regression head\n",
        "model = keras.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(1, activation=None)  # Regression output (no activation)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    loss='mse',  # Mean Squared Error for regression\n",
        "    metrics=['mae']  # Mean Absolute Error\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model (Phase 1: Frozen base)\n",
        "print(\"Phase 1: Training with frozen base model...\")\n",
        "\n",
        "history1 = model.fit(\n",
        "    train_images, train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS // 2,\n",
        "    validation_data=(val_images, val_labels),\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
